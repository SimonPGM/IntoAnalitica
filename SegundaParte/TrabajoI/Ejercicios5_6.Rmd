---
title: "Actividades clases 4 y 5"
author: "Juan José Galeano Arenas"
date: "26/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.pos = "center")
library(knitr)
library(tidyverse)
library(ggcorrplot)
library(plotly)
library(leaps)
library(olsrr)
library(latex2exp)
library(reshape2)
```

# Análisis descriptivo

A continuación se presenta un breve resumen de la estructura de la base 
de datos en cuestión

```{r BD_Act4}
Survival <- surgical %>%
  mutate(gender = as.factor(gender),
         alc_mod = as.factor(alc_mod),
         alc_heavy = as.factor(alc_heavy))
head(Survival, 5) %>% 
  kable(longtable = T, align = "c")
```

ahora se presentan algunos gráficos para tener una idea de cuales variables
pueden ser importantes para el modelo.

```{r hists_4}
#Funcion para sacar Sturges
MySturges <- function(x){
  pretty(range(x),
       n = nclass.Sturges(x), 
       min.n = 1)
}

#Continuas
# hist_bcs <- (ggplot(data = Survival, aes(x = bcs)) +
#   geom_histogram(breaks = MySturges(Survival$bcs), 
#                  col = "darkgreen", fill = "green") + 
#   labs(x = "Blood clotting score", y = "Frecuencia") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("hist_bcs.Rds")
# 
# hist_pindex <- (ggplot(data = Survival, aes(x = pindex)) +
#   geom_histogram(breaks = MySturges(Survival$pindex),
#                  col = "darkblue", fill = "blue") +
#   labs(x = "Prognostic index", y = "Frecuencia") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("hist_pindex.Rds")
# 
# hist_enzyme <- (ggplot(data = Survival, aes(x = enzyme_test)) +
#   geom_histogram(breaks = MySturges(Survival$enzyme_test),
#                  col = "darkred", fill = "red") +
#   labs(x = "Enzyme function test score", y = "Frecuencia") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("hist_enzyme.Rds")
# 
# hist_liver <- (ggplot(data = Survival, aes(x = enzyme_test)) +
#   geom_histogram(breaks = MySturges(Survival$enzyme_test),
#                  col = "gold", fill = "yellow") +
#   labs(x = "Liver function test score", y = "Frecuencia") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("hist_liver.Rds")

hist_bcs <- readRDS("PlotsJuanjo/hist_bcs.Rds")
hist_pindex <- readRDS("PlotsJuanjo/hist_pindex.Rds")
hist_enzyme <- readRDS("PlotsJuanjo/hist_enzyme.Rds")
hist_liver <- readRDS("PlotsJuanjo/hist_liver.Rds")

subplot(hist_bcs, hist_pindex, hist_enzyme, hist_liver,
        nrows = 2)
```

Observe que los histogramas para las distribuciones continuas son todos
asimétricos lo cual sugiere que estas variables no se distribuyen normal.

```{r boxplots_4_corr, warning=F}
# bp_age_gender <- (ggplot(data = Survival, 
#                         aes(x = gender, y = age, 
#                             col = gender)) +
#   geom_boxplot() +
#   labs(x = "Género", y = "Edad", colour = "Género") +
#   scale_x_discrete(labels = c("Masculino", "Femenino")) +
#   scale_colour_discrete(labels = c("M", "F")) +
#   theme_minimal()) %>%
#   ggplotly %>%
#   write_rds("bp_age_gender.Rds")
# 
# bp_age_mod <- (ggplot(data = Survival, aes(x = alc_mod, y = age,
#                                           col = alc_mod)) +
#   geom_boxplot() +
#   labs(x = "Historial de alcohol", y = "Edad", colour = "Alcohol") +
#   scale_x_discrete(labels = c("No toma", "Toma moderado")) +
#   scale_colour_discrete(labels = c("No", "Moderado")) +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("bp_age_mod.Rds")
# 
# bp_age_heavy <- (ggplot(data = Survival, aes(x = alc_heavy, y = age,
#                                           col = alc_heavy)) +
#   geom_boxplot() +
#   labs(x = "Historial de alcohol", y = "Edad", colour = "Alcohol") +
#   scale_x_discrete(labels = c("No toma", "Toma mucho")) +
#   scale_colour_discrete(labels = c("No", "Alto")) +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("bp_age_heavy.Rds")

#Matriz de correlación
# corrs <- data.frame(cor(Survival[, c(1:5, 9)]))
# corrs$Vars <- rownames(corrs)
# corrs.plot <- melt(corrs, id.vars = "Vars", na.rm = T)
# 
# corr_matrix <- (ggplot(corrs.plot, aes(variable, Vars, fill = value)) +
#   geom_tile() +
#   labs(fill = "Correlación", x = " ", y = " ", 
#        title = "Matriz de correlaciones") +
#   theme_minimal() +
#   theme(axis.text.x = element_text(angle = 90))) %>%
#   ggplotly() %>%
#   write_rds("corr_matrix.Rds")

bp_age_gender <- readRDS("PlotsJuanjo/bp_age_gender.Rds")
bp_age_mod <- readRDS("PlotsJuanjo/bp_age_mod.Rds")
bp_age_heavy <- readRDS("PlotsJuanjo/bp_age_heavy.Rds")
corr_matrix <- readRDS("PlotsJuanjo/corr_matrix.Rds")

subplot(bp_age_gender, bp_age_mod, corr_matrix, bp_age_heavy, nrows = 2)
```

Observe que las correlaciones entre las variables numéricas no es muy alta lo cual
es deseable para evitar potenciales problemas de multicolinealidad. 
Por otro lado, los boxplots no muestran diferencias entre los promedios 
de edad respecto al género o consumo de alcohol (ya sea moderado o alto).

# Selección de variables

## Mejor subconjunto

A continuación se realiza el proceso de selección de variables y modelos usando 
las metodologías directa (usando cross - validation) e indirecta (usando 
mejor subconjunto, selección hacia adelante y hacia atrás).

```{r Mejor_subconjunto}
all_covs <- regsubsets(y ~ ., nvmax = 8, data = Survival)
res_all_covs <- summary(all_covs)

# plots
# num_covs <- 1:8
# RSS <- res_all_covs$rss
# RSS_all_covs <- (ggplot(mapping = aes(x = num_covs, 
#                                       y = RSS)) +
#   geom_line() +
#   labs(x = "Número de covariables", y = "RSS", 
#        title = "Mejor subconjunto") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("RSS_all_covs.Rds")
# rm(RSS)
# 
# Adj_r2 <- res_all_covs$adjr2
# x_max_adjr2 <- which.max(res_all_covs$adjr2)
# max_adjr2 <- res_all_covs$adjr2[which.max(res_all_covs$adjr2)]
# Adj_R2_all_covs <- (ggplot(mapping = aes(x = num_covs, 
#                                          y = Adj_r2)) +
#                       geom_line() +
#                       labs(x = "Número de covariables", 
#                            y = "Coeficiente de determinación ajustado",
#                            title = "Mejor subconjunto") +
#                       geom_point(aes(x = x_max_adjr2,
#                                      y = max_adjr2), col = "red") + 
#                       theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("Adj_R2_all_covs.Rds")
# 
# Cp <- res_all_covs$cp
# x_min_Cp <- which.min(res_all_covs$cp)
# min_Cp <- res_all_covs$cp[which.min(res_all_covs$cp)]
# 
# Cp_all_covs <- (ggplot(mapping = aes(x = num_covs, 
#                                     y = Cp)) +
#   geom_line() +
#   labs(x = "Número de covariables", y = "Cp de Mallows",
#        title = "Mejor subconjunto") +
#   geom_point(aes(x = x_min_Cp, y = min_Cp), col = "red") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("Cp_all_covs.Rds")
# 
# BIC <- res_all_covs$bic
# x_min_BIC <- which.min(res_all_covs$bic)
# min_BIC <- res_all_covs$bic[which.min(res_all_covs$bic)]
# 
# BIC_all_covs <- (ggplot(mapping = aes(x = num_covs, y = BIC)) +
#   geom_line() +
#   labs(x = "Número de covariables", y = "BIC",
#        title = "Mejor subconjunto") +
#   geom_point(aes(x = x_min_BIC, y = min_BIC), col = "red") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("BIC_all_covs.Rds")
  
RSS_all_covs <- readRDS("PlotsJuanjo/RSS_all_covs.Rds")
Adj_R2_all_covs <- readRDS("PlotsJuanjo/Adj_R2_all_covs.Rds")
Cp_all_covs <- readRDS("PlotsJuanjo/Cp_all_covs.Rds")
BIC_all_covs <- readRDS("PlotsJuanjo/BIC_all_covs.Rds")

subplot(RSS_all_covs, Adj_R2_all_covs, Cp_all_covs,  BIC_all_covs,
        nrows = 2)
```

Observe que la suma cuadrática de los residuales no tiene una gran 
disminución a partir del modelo con 4 covariables. Por otro lado, según 
las métricas $R_{\text{Adj}}^2, \ C_p \text{ de Mallows y } BIC$ los mejores
modelos son aquellos que contienen 4 o 5 covariables, sin embargo no se sabe
cuales son dichos regresores por lo que se procede a buscarlos.

```{r matriz_covs_all}
#Problemas respecto a guardar los plots en objetos
R2_adj_all_covs_vars <- plot(all_covs, scale = "adjr2", 
                             main = TeX("$R_{Adj}^2$"))
Cp_all_covs_vars <- plot(all_covs, scale = "Cp", main = TeX("$C_p$"))
BIC_all_covs_vars <- plot(all_covs, scale = "bic", main = "BIC")
```

Se tienen las siguiente covariables como las más importantes

* bcs, pindex, enzyme_test, liver_test y alc_heavy según $R_{\text{Adj}}^2$
* bcs, pindex, enzyme_test y alc_heavy según el $C_p$ de Mallows y el BIC

## Selección hacia adelante

```{r forward_selection}
rm(list = setdiff(ls(), "Survival"))
forward_selection <- regsubsets(y ~ ., nvmax = 8, data = Survival, 
                                method = "forward")
res_forward <- summary(forward_selection)

# plots
# num_covs <- 1:8
# RSS <- res_forward$rss
# RSS_forward <- (ggplot(mapping = aes(x = num_covs, 
#                                       y = RSS)) +
#   geom_line() +
#   labs(x = "Número de covariables", y = "RSS", 
#        title = "Selección hacia adelante") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("RSS_forward.Rds")
# rm(RSS)
# 
# Adj_r2 <- res_forward$adjr2
# x_max_adjr2 <- which.max(res_forward$adjr2)
# max_adjr2 <- res_forward$adjr2[which.max(res_forward$adjr2)]
#
# Adj_R2_forward <- (ggplot(mapping = aes(x = num_covs, 
#                                          y = Adj_r2)) +
#                       geom_line() +
#                       labs(x = "Número de covariables", 
#                            y = "Coeficiente de determinación ajustado",
#                            title = "Selección hacia adelante") +
#                       geom_point(aes(x = x_max_adjr2,
#                                      y = max_adjr2), col = "red") + 
#                       theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("Adj_R2_forward.Rds")
# 
# Cp <- res_forward$cp
# x_min_Cp <- which.min(res_forward$cp)
# min_Cp <- res_forward$cp[which.min(res_forward$cp)]
# 
# Cp_forward <- (ggplot(mapping = aes(x = num_covs, 
#                                     y = Cp)) +
#   geom_line() +
#   labs(x = "Número de covariables", y = "Cp de Mallows",
#        title = "Selección hacia adelante") +
#   geom_point(aes(x = x_min_Cp, y = min_Cp), col = "red") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("Cp_forward.Rds")
# 
# BIC <- res_forward$bic
# x_min_BIC <- which.min(res_forward$bic)
# min_BIC <- res_forward$bic[which.min(res_forward$bic)]
# 
# BIC_forward <- (ggplot(mapping = aes(x = num_covs, y = BIC)) +
#   geom_line() +
#   labs(x = "Número de covariables", y = "BIC",
#        title = "Selección hacia adelante") +
#   geom_point(aes(x = x_min_BIC, y = min_BIC), col = "red") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("BIC_forwards.Rds")

RSS_forward <- readRDS("PlotsJuanjo/RSS_forward.Rds")
Adj_R2_forward <- readRDS("PlotsJuanjo/Adj_R2_forward.Rds")
Cp_forward <- readRDS("PlotsJuanjo/Cp_forward.Rds")
BIC_forward <- readRDS("PlotsJuanjo/BIC_forwards.Rds")

subplot(RSS_forward, Adj_R2_forward, Cp_forward, BIC_forward, 
        nrows = 2)
```

En esta situación, $R_{\text{Adj}}^2, \ C_p \text{ de Mallows y BIC}$ llegan a 
un concenso y todos consideran que el mejor modelo es aquel que considera 5 
covariables; note además que la suma cuadrática de los residuales deja de tener
un cambio notable justamente en el mejor modelo con 5 covariables.

```{r matriz_forward}
R2_adj_forward_vars <- plot(forward_selection, scale = "adjr2", 
                             main = TeX("$R_{Adj}^2$"))
Cp_forward_vars <- plot(forward_selection, scale = "Cp", main = TeX("$C_p$"))
BIC_forward_vars <- plot(forward_selection, scale = "bic", main = "BIC")
```

Todas las métricas de desempeño consideradas llegan a que el mejor modelo es 
aquel que usa las covariables bcs, pindex, enezyme_test, liver_test y alc_heavy.

## Selección hacia atrás 

```{r backward_selection}
rm(list = setdiff(ls(), "Survival"))
backward_selection <- regsubsets(y ~ ., nvmax = 8, data = Survival, 
                                method = "backward")
res_backward <- summary(backward_selection)

# plots
# num_covs <- 1:8
# RSS <- res_backward$rss
# RSS_backward <- (ggplot(mapping = aes(x = num_covs, 
#                                       y = RSS)) +
#   geom_line() +
#   labs(x = "Número de covariables", y = "RSS", 
#        title = "Selección hacia atrás") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("RSS_backward.Rds")
# rm(RSS)
# 
# Adj_r2 <- res_backward$adjr2
# x_max_adjr2 <- which.max(res_backward$adjr2)
# max_adjr2 <- res_backward$adjr2[which.max(res_backward$adjr2)]
# 
# Adj_R2_backward <- (ggplot(mapping = aes(x = num_covs, 
#                                          y = Adj_r2)) +
#                       geom_line() +
#                       labs(x = "Número de covariables", 
#                            y = "Coeficiente de determinación ajustado",
#                            title = "Selección hacia atrás") +
#                       geom_point(aes(x = x_max_adjr2,
#                                      y = max_adjr2), col = "red") + 
#                       theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("Adj_R2_backward.Rds")
# 
# Cp <- res_backward$cp
# x_min_Cp <- which.min(res_backward$cp)
# min_Cp <- res_backward$cp[which.min(res_backward$cp)]
# 
# Cp_backward <- (ggplot(mapping = aes(x = num_covs, 
#                                     y = Cp)) +
#   geom_line() +
#   labs(x = "Número de covariables", y = "Cp de Mallows",
#        title = "Selección hacia atrás") +
#   geom_point(aes(x = x_min_Cp, y = min_Cp), col = "red") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("Cp_backward.Rds")
# 
# BIC <- res_backward$bic
# x_min_BIC <- which.min(res_backward$bic)
# min_BIC <- res_backward$bic[which.min(res_backward$bic)]
# 
# BIC_backward <- (ggplot(mapping = aes(x = num_covs, y = BIC)) +
#   geom_line() +
#   labs(x = "Número de covariables", y = "BIC",
#        title = "Selección hacia atrás") +
#   geom_point(aes(x = x_min_BIC, y = min_BIC), col = "red") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("BIC_backward.Rds")

RSS_backward <- readRDS("PlotsJuanjo/RSS_backward.Rds")
Adj_R2_backward <- readRDS("PlotsJuanjo/Adj_R2_backward.Rds")
Cp_backward <- readRDS("PlotsJuanjo/Cp_backward.Rds")
BIC_backward <- readRDS("PlotsJuanjo/BIC_backward.Rds")

subplot(RSS_backward, Adj_R2_backward, Cp_backward, BIC_backward, 
        nrows = 2)

```


```{r matriz_backward}
R2_adj_backward_vars <- plot(backward_selection, scale = "adjr2", 
                             main = TeX("$R_{Adj}^2$"))
Cp_backward_vars <- plot(backward_selection, scale = "Cp", main = TeX("$C_p$"))
BIC_backward_vars <- plot(backward_selection, scale = "bic", main = "BIC")
```

Las conclusiones del método backward son las mismas que las del método de mejor
subconjunto, escogiendo como mejores covariables:

* bcs, pindex, enezyme_test, liver_test y alc_heavy según $R_{\text{Adj}}^2$ 
* bcs, pindex, enezyme_test, y alc_heavy según $C_p$ de Mallows y el BIC.

## Observaciones

* En general, las covariables bcs, pindex, enezyme_test y alc_heavy deben ser
consideradas para explicar la variabilidad de la respuesta, pues fueron escogidas 
por la métricas que previenen el sobreajuste en cada caso.
* Se puede considerar el regresor liver_test ya que figuró como una variable
importante en algunos ocasiones (todos los modelos de selección hacia adelante 
y algunos de selección hacia atrás y mejor subconjunto). 
* Las demás covariables no figuraron en los modelos considerados, por lo tanto 
estas no deben ser muy útiles para explicar la variabilidad de la respuesta y 
se pueden omitir.

# Selección usando Cross - Validation

En este punto, se procede a seleccionar el mejor modelo usando cross - validation, 
en particular con las metodologías train - test split y K-Fold

## Train - Test Split

```{r train_test_split}
set.seed(22)
indexes <- sample(1:nrow(Survival), floor(nrow(Survival) * 0.7))
train <- Survival[indexes, ]
test <- Survival[-indexes, ]

#Usando las diferentes metodologías
#Mejor subconjunto
best_subset <- regsubsets(y ~ ., data = train,
                          nvmax = 8)

#Forward selection
best_forward <- regsubsets(y ~ ., data = train,
                          nvmax = 8, method = "forward")
#Backward selection
best_backward <- regsubsets(y ~ ., data = train,
                          nvmax = 8, method = "backward")
#Usando la función de Mauricio (Pag 34 diapositivas Clase 4)
predict.regsubsets =function (object,newdata,y){
  form<-as.formula(object$call[[2]])
  mat<-model.matrix(form ,newdata)
  val.errors = rep(NA, (ncol(mat) - 1))
  for(i in 1:length(val.errors)){
    coefi<-coef(object ,id=i)
    xvars<-names (coefi)
    pred<-mat[,xvars]%*%coefi
    val.errors [i]= mean((y-pred)^2)
  }
  val.errors
}

MSE_best_subset <- predict.regsubsets(best_subset, test, test$y)
MSE_best_forward <- predict.regsubsets(best_forward, test, test$y)
MSE_best_backward <- predict.regsubsets(best_backward, test, test$y)

#Plots 
#Mejor subconjunto
# num_covs <- 1:8
# x_min_mse <- which.min(MSE_best_subset)
# min_mse <- MSE_best_subset[x_min_mse]
# 
# best_subset_mses <- (ggplot(mapping = aes(x =num_covs, 
#                                          y = MSE_best_subset)) +
#   geom_line() +
#   geom_point(aes(x = x_min_mse, y = min_mse), col = "red") +
#   labs(x = "Número de covariables", y = "MSE", 
#        title = "Mejor subconjunto")+
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("best_subset_mses.Rds")
# 
# #Forward
# x_min_mse <- which.min(MSE_best_forward)
# min_mse <- MSE_best_forward[x_min_mse]
# 
# best_forward_mses <- (ggplot(mapping = aes(x = num_covs, y = MSE_best_forward)) +
#   geom_line() +
#   geom_point(aes(x = x_min_mse, y = min_mse), col = "red") +
#   labs(x = "Número de covariables", y = "MSE", title = "Selección hacia adelante") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("best_forward_mses.Rds")
# 
# #Backward
# x_min_mse <- which.min(MSE_best_backward)
# min_mse <- MSE_best_backward[x_min_mse]
# 
# best_backward_mses <- (ggplot(mapping = aes(x = num_covs, y = MSE_best_backward)) +
#   geom_line() +
#   geom_point(aes(x = x_min_mse, y =  min_mse), col = "red") +
#   labs(x = "Número de covariables", y = "MSE", title = "Selección hacia atrás") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("best_backward_mses.Rds")

best_subset_mses <- readRDS("PlotsJuanjo/best_subset_mses.Rds")
best_forward_mses <- readRDS("PlotsJuanjo/best_forward_mses.Rds")
best_backward_mses <- readRDS("PlotsJuanjo/best_backward_mses.Rds")

subplot(best_subset_mses, best_forward_mses, best_backward_mses, nrows = 3)
```


Según MSE los mejores modelos usando los métodos del mejor subconjunto,
selección adelante y hacia atrás respectivamente son aquellos con 8 y 6 
covariables (mejor subconjunto y selección llegan al mismo resultado), 
sin embargo, se puede notar que a partir de los modelos de 4 covariables 
la disminución de este es mínimo y se pueden considerar mejores al ser más
parsimoniosos, además como se vió con las métricas $R_{\text{Adj}}^2, C_p, BIC$,
los mejores modelos son aquellos que tienen 4 o 5 covariables por lo que se 
recomienda tomar dichos modelos.

## K - Fold Cross Validation

Se usan 3 capas porque la base de datos tiene pocas observaciones

```{r}
set.seed(2)
k <- 3 
k_fold_index <- sample(1:nrow(Survival))
divs <- nrow(Survival)/k
obs <- 1
k_train <- list()
for(i in 1:k){
  k_train[[i]] <- k_fold_index[obs:(i*divs)]
  obs <- obs + divs
}

#Mejor subconjunto
k_fold_errors_subset <- matrix (NA , k, 8, dimnames = list(NULL,paste (1:8)))

for(i in 1:k){
  current_fit <- regsubsets(y ~ ., data = Survival[-(k_train[[i]]), ], nvmax = 8)
  pred <- predict.regsubsets(current_fit, Survival[k_train[[i]], ],
                             Survival$y[k_train[[i]]])
  k_fold_errors_subset[i, ] <- pred
}

mean_k_fold_errors_subset <- apply(k_fold_errors_subset, 2, mean)

#Forward
k_fold_errors_forward <- matrix (NA , k, 8, dimnames = list(NULL,paste (1:8)))

for(i in 1:k){
  current_fit <- regsubsets(y ~ ., data = Survival[-(k_train[[i]]), ], 
                            nvmax = 8, method = "forward")
  pred <- predict.regsubsets(current_fit, Survival[k_train[[i]], ],
                             Survival$y[k_train[[i]]])
  k_fold_errors_forward[i, ] <- pred
}
mean_k_fold_errors_forward <- apply(k_fold_errors_forward, 2, mean)

#Backward
k_fold_errors_backward <- matrix (NA , k, 8, dimnames = list(NULL,paste (1:8)))

for(i in 1:k){
  current_fit <- regsubsets(y ~ ., data = Survival[-(k_train[[i]]), ], 
                            nvmax = 8, method = "backward")
  pred <- predict.regsubsets(current_fit, Survival[k_train[[i]], ],
                             Survival$y[k_train[[i]]])
  k_fold_errors_backward[i, ] <- pred
}
mean_k_fold_errors_backward <- apply(k_fold_errors_backward, 2, mean)
```

```{r Plots_K_Fold}
# num_covs <- 1:8
# 
# #Mejor subconjunto
# MSE <- mean_k_fold_errors_subset
# 
# x_min_mse <- which.min(mean_k_fold_errors_subset)
# min_mse <- mean_k_fold_errors_subset[x_min_mse]
# kfold_subset <- (ggplot(mapping = aes(x = num_covs, y = MSE)) +
#   geom_line() +
#   geom_point(aes(x = x_min_mse, y = min_mse), col = "red") +
#   labs(x = "Número de covariables", title = "Mejor subconjunto") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("kfold_subset.Rds")
# 
# #Forward
# MSE <- mean_k_fold_errors_forward
# 
# x_min_mse <- which.min(mean_k_fold_errors_forward)
# min_mse <- mean_k_fold_errors_forward[x_min_mse]
# kfold_forward <- (ggplot(mapping = aes(x = num_covs, y = MSE)) +
#   geom_line() +
#   geom_point(aes(x = x_min_mse, y = min_mse), col = "red") +
#   labs(x = "Número de covariables", title = "Selección hacia adelante") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("kfold_forward.Rds")
# 
# #Backward
# MSE <- mean_k_fold_errors_backward
# 
# x_min_mse <- which.min(mean_k_fold_errors_backward)
# min_mse <- mean_k_fold_errors_backward[x_min_mse]
# kfold_backward <- (ggplot(mapping = aes(x = num_covs, y = MSE)) +
#   geom_line() +
#   geom_point(aes(x = x_min_mse, y = min_mse), col = "red") +
#   labs(x = "Número de covariables", title = "Selección hacia atrás") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("kfold_backward.Rds")

kfold_subset <- readRDS("PlotsJuanjo/kfold_subset.Rds")
kfold_forward <- readRDS("PlotsJuanjo/kfold_forward.Rds")
kfold_backward <- readRDS("PlotsJuanjo/kfold_backward.Rds")

subplot(kfold_subset, kfold_forward, kfold_backward, nrows = 3)
```


Nuevamente, el método de mejor subconjunto y el de selección hacia atrás 
concuerdan con el número de covariables que dan menor MSE mientras que el 
método de selección hacia adelante considera mejor el de 5 covariables.

## Leave One Out Cross Validation

Dado la escacez de observaciones, esta metología de cross validation es la más
fiable de todas.

```{r loocv}
rows <- nrow(Survival)
#Mejor subconjunto
loocv_errors_subset <- matrix (NA , rows, 8, 
                               dimnames = list(NULL,paste (1:8)))

for(i in 1:rows){
  current_fit <- regsubsets(y ~ ., data = Survival[-i, ], nvmax = 8)
  pred <- predict.regsubsets(current_fit, Survival[i, ],
                             Survival$y[i])
  loocv_errors_subset[i, ] <- pred
}
mean_loocv_errors_subset <- apply(loocv_errors_subset, 2, mean)

#Forward
loocv_errors_forward <- matrix (NA , rows, 8, 
                               dimnames = list(NULL,paste (1:8)))

for(i in 1:rows){
  current_fit <- regsubsets(y ~ ., data = Survival[-i, ], 
                            nvmax = 8, method = "forward")
  pred <- predict.regsubsets(current_fit, Survival[i, ],
                             Survival$y[i])
  loocv_errors_forward[i, ] <- pred
}
mean_loocv_errors_forward <- apply(loocv_errors_forward, 2, mean)

#Backward
loocv_errors_backward <- matrix (NA , rows, 8, 
                               dimnames = list(NULL,paste (1:8)))

for(i in 1:rows){
  current_fit <- regsubsets(y ~ ., data = Survival[-i, ], 
                            nvmax = 8, method = "backward")
  pred <- predict.regsubsets(current_fit, Survival[i, ],
                             Survival$y[i])
  loocv_errors_backward[i, ] <- pred
}
mean_loocv_errors_backward <- apply(loocv_errors_backward, 2, mean)
```

```{r loocv_plots}
# num_covs <- 1:8
# 
# #Mejor subconjunto
# MSE <- mean_loocv_errors_subset
# x_min <- which.min(mean_loocv_errors_subset)
# min_mse <- MSE[x_min]
# 
# loocv_subset_plot <- (ggplot(mapping = aes(x = num_covs, y = MSE)) +
#   geom_line() +
#   geom_point(aes(x = x_min, y = min_mse), col = "red") +
#   labs(x = "Número de covariables", y = "MSE", title = "Mejor subconjunto") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("loocv_subset_plot.Rds")
# 
# #Forward
# MSE <- mean_loocv_errors_forward
# x_min <- which.min(mean_loocv_errors_forward)
# min_mse <- MSE[x_min]
# 
# loocv_forward_plot <- (ggplot(mapping = aes(x = num_covs, y = MSE)) +
#   geom_line() +
#   geom_point(aes(x = x_min, y = min_mse), col = "red") +
#   labs(x = "Número de covariables", y = "MSE", title = "Selección hacia adelante") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("loocv_forward_plot.Rds")
# 
# #Backward
# MSE <- mean_loocv_errors_backward
# x_min <- which.min(mean_loocv_errors_backward)
# min_mse <- MSE[x_min]
# 
# loocv_backward_plot <- (ggplot(mapping = aes(x = num_covs, y = MSE)) +
#   geom_line() +
#   geom_point(aes(x = x_min, y = min_mse), col = "red") +
#   labs(x = "Número de covariables", y = "MSE", title = "Selección hacia atrás") +
#   theme_minimal()) %>%
#   ggplotly() %>%
#   write_rds("loocv_backward_plot.Rds")

loocv_subset_plot <- readRDS("PlotsJuanjo/loocv_subset_plot.Rds")
loocv_forward_plot <- readRDS("PlotsJuanjo/loocv_forward_plot.Rds")
loocv_backward_plot <- readRDS("PlotsJuanjo/loocv_backward_plot.Rds")

subplot(loocv_subset_plot, loocv_forward_plot, loocv_backward_plot, nrows = 3)
```

Finalmente, al usar LOOCV todos los métodos llegan a que el modelo con menor MSE es
aquel que usa 5 covariables (se puede verificar que en este caso particular, 
los 3 MSE son iguales)

# Conclusiones

```{r best_fit, eval=F}
best_fit <- regsubsets(y ~ ., data = Survival, nvmax = 8)
coef(best_fit, 5)
```


Después de analizar el desempeño de los modelos usando métricas indirectas 
(como $R_{\text{Adj}}^2, \ C_p, \ BIC$) y directas (MSE) se concluye que el 
número óptimo de covariables a usar es 5 pues en la métrica directa más 
adecuada para la situación presentada (LOOCV) los modelos con este número 
de covariables fueron los que obtuvieron un menor MSE. Por otro lado, según 
las métricas indirectas el número adecuado de covariables es 4 o 5 lo cual es 
coherente con lo mencionado anteriormente. Finalmente se escoge el modelo de 5
covariables que tuvo un menor MSE, dicho modelo usó las covariables bcs, pindex,
enzyme_test, liver_test y alc_heavy, las cuales fueron detectadas previamente 
como las más importantes gracias a los métodos indirectos.

