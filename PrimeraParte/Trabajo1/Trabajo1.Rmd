---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
- \usepackage{xcolor}
- \usepackage{cancel}
- \usepackage{array}
- \usepackage{float}
- \usepackage{multirow}
output:
  pdf_document:
    number_sections: true
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: "es"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(kableExtra)
library(class)
```

\input{titlepage}
\thispagestyle{empty}
\tableofcontents

\newpage

\pagestyle{myheadings}
\setcounter{page}{3}

# Ejercicio (1)

# Ejercicio (2)

\subsection{Análisis descriptivo}

Antes de realizar cualquier modelo predictivo o análisis inferencial es importante 
hacer un análisis descriptivo para formular hipótesis.
Teniendo en cuenta que la variable género es cualitativa, un diagrama de dispersión
entre dicha variable y afh no sería adecuado, por lo que se realiza un
diagrama de cajas el cual logra representar de forma más clara el comportamiento de
una variable continua en distintas categorías.

```{r boxplot, echo=F, fig.align='center'}
datos <- read.csv("datosage_6.csv", header = T) %>%
  mutate(gender = as.factor(gender))

ggplot(data = datos) +
  geom_boxplot(mapping = aes(x = gender, y = afh, color = gender)) +
  scale_x_discrete(labels = c("Femenino", "Masculino")) + 
  scale_colour_discrete(labels = c("F", "M")) +
  labs(colour = "Género") + 
  xlab("Género") +
  theme_minimal()
```

De este diagrama de cajas se pueden sacar algunas conclusiones:

* Las cajas se traslapan por lo que se puede pensar que el afh promedio de los hombres 
no es diferente respecto al de las mujeres.
* La amplitud de las cajas es muy similar sugiriendo que la variabilidad no cambia 
según el género.
* La mediana se encuentra en el centro de las cajas en ambos casos, 
sugiriendo que una distribución simétrica se ajustaría bien a los datos.

Dicho lo anterior se procede a graficar un histograma de la variable respuesta o output
sin discriminar por género:

```{r histograma, echo=F, fig.align='center'}
ggplot(data = datos, aes(x = afh)) +
  geom_histogram(binwidth = 5, 
                 color = "darkgreen", fill = "lightgreen") +
  ylab("Frecuencia") +
  theme_minimal()
```

El histograma para afh muestra una ligera asimetría negativa, sin embargo no se puede
afirmar si el pequeño sesgo es estadísticamente significativo porque en casos que no son
tan evidentes la decisión depende bastante del analista, lo cual sugiere que valdría
la pena hacer un test formal para contrastar: 

$$
\begin{aligned}
\begin{cases}
H_0: \text{La variable afh se distribuye normal} \\
H_1: \text{La variable afh NO se distribuye normal}
\end{cases}
\end{aligned}
$$

Recuerde que uno de los supuestos básicos del modelo de regresión lineal es que la
variable respuesta se distribuya normal, lo cual refuerza la idea de probar dicha 
hipótesis.

Cabe resaltar que lo visto en el boxplot fue un análisis discriminando por género y
la normalidad en dimensiones bajas no implica la de dimensiones altas.

**Notas** 

* Todas las entradas de la variable edad es 6 lo cual no aporta ningún tipo de
información útil para análisis descriptivo o modelación.
* Las bases de datos relacionales tiene un atributo obligatorio (columna ó combinación
de columnas) conocido como clave primaria la cual ayuda a identificar de forma única a
cada fila; teniendo en cuenta que las variable id y X tienen 150 entradas únicas 
(el mismo número de observaciones) se asume que estas variables forman la clave
primaria de esta base de datos y aunque pudiera existir algún tipo de correlación 
entre estas y el output, se debería más a la casualidad que a la causalidad.

\subsection{Modelos considerados}

En la etapa de modelación, se considera la regresión lineal simple como modelo
paramétrico usando afh como variable respuesta y al género como covariable mientras
que la regresión loess se usa como modelo no paramétrico.

Para la construcción de modelos se tomó el 80\% de observaciones de la base de datos
en la modelación y se dejó el 20\% como datos de prueba.

```{r train_test, echo=F}
#Partiendo los datos aleatoriamente para la modelacion
set.seed(3435)
indexes <- sample(1:dim(datos)[1], 0.8 * dim(datos)[1])

#Particion de los datos
train_data <- datos[indexes, ] %>%
  select(afh, gender) %>%
  mutate(gender = as.numeric(gender))

test_data <- datos[-indexes, ] %>%
  select(gender) %>%
  mutate(gender = as.numeric(gender))

test_response <- datos[-indexes, ] %>%
  select(afh) %>%
  unlist() %>%
  as.numeric()

#NOTA: del factor con niveles 0 y 1, siendo numericos se convierten en 1 y 2
#respectivamente
```


```{r parametrico, echo=F, warning=F}
#Se usa datos en los indices necesarios porque en dicha bd, gender es un factor
#(lm sí soporta factores)
param <- lm(afh ~ gender, data = datos[indexes, c("afh", "gender")])
```

Para la construcción del modelo no paramétrico, se tomaron distintos valores del span
y se escogió el que produjo un menor MSE en los datos de entrenamiento.

```{r busqueda_span, echo=F, warning=F, message=F}
spans <- seq(from = 0.05, to = 0.95, by = 0.025)
mse <- c()
for(i in spans){
  mod_actual <- loess(afh ~ gender, data = train_data, span = i)
  mse <- append(mse, Metrics::mse(train_data$afh, fitted(mod_actual)))
}
#Nota: Para los spans escogidos se cumple que a partir de 0.575 el mse de
#entrenamiento siempre es 31.51
```

Luego de revisar los valores del MSE para diferentes valores de span, se encontró algo
curioso; para valores de span menores a 0.575 se produjieron NaN mientras que para
valores mayores o iguales a 0.575 el MSE de entrenamiento fue el mismo para todos los
modelos con un valor de 31.51, en resumen:

$$
MSE(\text{Span}) = \begin{cases}
\text{NaN} \hspace{.2in} \text{Span} \ < \ 0.575 \\
31.51 \hspace{.2in} \text{Span}  \geq \ 0.575
\end{cases}
$$
Como el valor del Span no importa para valores mayores o iguales 0.575 en este caso
particular, se escoge uno de 0.75 simplemente por buena práctica, ya que si se le 
añade demasiada flexibilidad al modelo este tendría mucha varianza porque sería 
muy sensible a pequeños cambios en los datos.

```{r mod_no_parametrico, echo=F, warning=F, message=F}
#Aqui si se usa la base train porque gender es numerica para que loess funcione
nparam <- loess(afh ~ gender, data = train_data)
```

Dicho todo esto, se procede a realizar predicciones con los datos de prueba y
posteriormente se realiza el calculo de los MSE correspondientes los cuales se 
presentan en la siguiente tabla.

```{r predicts, echo=F}
#Modelo lineal
afh_hat_param <- predict(param, data.frame(gender =  datos[-indexes, 5]))
mse_param <- Metrics::mse(test_response, afh_hat_param)

#Modelo loess (No parametrico)
afh_hat_np <- predict(nparam, test_data)
mse_np <- Metrics::mse(test_response, afh_hat_np)

#Tabla comparativa
comparacion <- data.frame(MSE = c(mse_param, mse_np) %>% round(3))
rownames(comparacion) <- c("Lineal", "Loess")
kable(comparacion, longtable = T, escape = F, booktabs = T)
```

Observe que ambos modelos tienen el mismo MSE por lo cual tienen el mismo poder
predictivo en la situación dada.

En este caso es más adecuado escoger el modelo lineal porque tiene el mismo poder
predictivo que el loess, sin embargo la interpretabilidad de este último es demasiado compleja (por no decir que no se puede interpretar). Por otro lado, una de las mayores ventajas de los modelos lineales es que son muy interpretables por lo cual este le saca ventaja al modelo loess en esta situación particular y por eso se concluye que es el adecuado en este caso.

# Ejercicio (3) 

Ejercicio 7, texto guía (primera edición), página 53. Hágalo también en R.

La siguiente tabla proporciona un conjunto de datos de entrenamiento que contiene seis observaciones, tres predictores y una variable de respuesta cualitativa.

```{r tabla1, include=FALSE}

# Lectura de datos
datos3 <- read.csv("datos3.txt", sep = " ", encoding = "UTF-8") 

```

```{r tabla2, echo=FALSE}

# Presentación de tabla en el documento
kable(
      datos3,
      booktabs = T,
      col.names = c("Obs.", "$X_1$", "$X_2$", "$X_3$", "$Y$"),
      align = rep('c', 5),
      escape = F
      ) %>%
      kable_styling(latex_options = c("HOLD_position")) 
```

Suponga que deseamos usar este conjunto de datos para hacer una predicción para $Y$ cuando
$X_1 = X_2 = X_3 = 0$ usando K vecinos más cercanos.

## Literal (a)

Calcule la distancia euclidiana entre cada observación y el punto de prueba, \newline $X_1 = X_2 = X_3 = 0$.

```{r dist-euc-calculos, include=FALSE}
# Se salcula la distancia euclideana con respecto al nuevo punto.
punto <- c(0, 0, 0)

datos3 <- datos3 %>%
            mutate(dis = sqrt( (X1 - punto[1])^2 + (X2 - punto[2])^2 + (X3 - punto[3])^2 ))

```

Se procede a calcular la distancia euclideana con respecto a $X_1 = X_2 = X_3 = 0$ para cada una de las observaciones de la forma $(X_{1i}, X_{2i}, X_{3i}); i = 1, ..., 6$ como: 

$$ \text{Distancia Euclideana Obs. i} = \sqrt{(X_{1i} - 0)^2 + (X_{2i} - 0)^2 + (X_{3i} - 0)^2}$$

```{r dist-euc-tabla, echo=FALSE}
kable(
      datos3[c(1:4, 6, 5)],
      booktabs = T,
      col.names = c("Obs.", "$X_1$", "$X_2$", "$X_3$", "Distancia euclideana", "$Y$"),
      align = rep('c', 5),
      escape = F
      ) %>%
      kable_styling(latex_options = c("HOLD_position")) 
```

## Literal (b)

¿Cuál es nuestra predicción con K = 1? ¿Por qué?

Note que para el primer literal se NO se realizó una estandarización de los datos. Siguiendo las recomendaciones proporcionadas en las sesiones de clase, se realiza nuevamente lo solicitado en el primer literal con una base de datos estandarizada (incluyendo el nuevo dato sobre el cual se quiere predecir.). 

Se escala cada una de las variables restando por su media y diviendo sobre su desviación estándar, se obtiene ($X_1', X_2', X_3'$).

```{r dist-euc-scale-calculos, include=FALSE}
# Se añade la nueva observación y se escalan los datos
datos3_est <- datos3[,1:5] %>%
                add_row(Obs. = 7,
                        X1 = 0,
                        X2 = 0,
                        X3 = 0, 
                        Y = "Desconocido") %>%
                mutate(X1 = scale(X1),
                       X2 = scale(X2),
                       X3 = scale(X3)) 

# Punto sobre el cual se calcula la distancia
punto <- as.numeric(datos3_est[7,2:4])

# Distancia
datos3_est <- datos3_est %>%
                mutate(dist = sqrt( (X1 - punto[1])^2 + (X2 - punto[2])^2 + (X3 - punto[3])^2 ) )


```

```{r dist-euc-scale-tabla, echo=FALSE}

# Presentación de tabla en el documento
kable(
      datos3_est[c(1:4, 6, 5)],
      booktabs = T,
      col.names = c("Obs.", "$X_1'$", "$X_2'$", "$X_3'$", "Distancia euclideana", "Y"),
      align = rep('c', 6),
      escape = F
      ) %>%
      kable_styling(latex_options = c("HOLD_position"))  %>%
      row_spec(5, background = "green")
```

De esta forma, se ve que la observación más cercana corresponde a la número 5, esta observación es verde. Así pues, utilizando un $K = 1$, la predicción para la nueva observación sería \textbf{verde.}

## Literal (c)

¿Cuál es nuestra predicción con K = 3? ¿Por qué?

Recurriendo a la tabla presentada previamente e identificando las tres observaciones más cercanas (las cuales se resaltan), se tiene que 2 de las 3 observaciones son verdes por lo que la predicción para la nueva observación sería \textbf{verde.}

```{r dist-euc-scale-tabla2, echo=FALSE}

# Presentación de tabla en el documento
kable(
      datos3_est[c(1:4, 6, 5)],
      booktabs = T,
      col.names = c("Obs.", "$X_1'$", "$X_2'$", "$X_3'$", "Distancia euclideana", "Y"),
      align = rep('c', 6),
      escape = F
      ) %>%
      kable_styling(latex_options = c("HOLD_position"))  %>%
      row_spec(c(4, 5), background = "green") %>%
      row_spec(6, background = "red")
```

## Literal (d)

Si el límite de decisión de Bayes en este problema es muy no lineal, entonces esperaríamos que el mejor valor para K fuera grande o ¿pequeña? ¿Por qué?

Un límite de decisión de Bayes altamente NO lineal implica que zonas espaciales donde una nueva observación es clasificada a la categoría verde están muy cerca (colindan) con zonas espaciales donde nuevas observaciones son clasificadas como rojas. 

Elegir un $K$ relativamente grande implicaría que para la clasificación se tomaría una zona espacial grande y dado lo descrito anteriormente, sería más probable considerar puntos para la clasificación que hacen parte de una clase diferente, lo que aumentaría la probabilidad de una clasificación incorrecta, se esperaría pues que el valor más adecuado para $K$ sea relativamente \textbf{pequeño.}

El desarrollo en R utilizando la función `knn()` de la librería `class` está disponible en los anexos.

# Ejercicio (4)

# Anexos

## Ejercicio 2

Código para el análisis descriptivo y construcción de modelos

```{r  fig.align='center'}
datos <- read.csv("datosage_6.csv", header = T) %>%
  mutate(gender = as.factor(gender))

ggplot(data = datos) +
  geom_boxplot(mapping = aes(x = gender, y = afh, color = gender)) +
  scale_x_discrete(labels = c("Femenino", "Masculino")) + 
  scale_colour_discrete(labels = c("F", "M")) +
  labs(colour = "Género") + 
  xlab("Género") +
  theme_minimal()
```


```{r fig.align='center'}
ggplot(data = datos, aes(x = afh)) +
  geom_histogram(binwidth = 5, 
                 color = "darkgreen", fill = "lightgreen") +
  ylab("Frecuencia") +
  theme_minimal()
```


```{r}
#Partiendo los datos aleatoriamente para la modelacion
set.seed(3435)
indexes <- sample(1:dim(datos)[1], 0.8 * dim(datos)[1])

#Particion de los datos
train_data <- datos[indexes, ] %>%
  select(afh, gender) %>%
  mutate(gender = as.numeric(gender))

test_data <- datos[-indexes, ] %>%
  select(gender) %>%
  mutate(gender = as.numeric(gender))

test_response <- datos[-indexes, ] %>%
  select(afh) %>%
  unlist() %>%
  as.numeric()

#NOTA: del factor con niveles 0 y 1, siendo numericos se convierten en 1 y 2
#respectivamente
```


```{r warning=F}
#Se usa datos en los indices necesarios porque en dicha bd, gender es un factor
#(lm sí soporta factores)
param <- lm(afh ~ gender, data = datos[indexes, c("afh", "gender")])
```


```{r warning=F, message=F}
spans <- seq(from = 0.05, to = 0.95, by = 0.025)
mse <- c()
for(i in spans){
  mod_actual <- loess(afh ~ gender, data = train_data, span = i)
  mse <- append(mse, Metrics::mse(train_data$afh, fitted(mod_actual)))
}
#Nota: Para los spans escogidos se cumple que a partir de 0.575 el mse de
#entrenamiento siempre es 31.51
```


```{r warning=F, message=F}
#Aqui si se usa la base train porque gender es numerica para que loess funcione
nparam <- loess(afh ~ gender, data = train_data)
```


```{r}
#Modelo lineal
afh_hat_param <- predict(param, data.frame(gender =  datos[-indexes, 5]))
mse_param <- Metrics::mse(test_response, afh_hat_param)

#Modelo loess (No parametrico)
afh_hat_np <- predict(nparam, test_data)
mse_np <- Metrics::mse(test_response, afh_hat_np)

#Tabla comparativa
comparacion <- data.frame(MSE = c(mse_param, mse_np) %>% round(3))
rownames(comparacion) <- c("Lineal", "Loess")
kable(comparacion, longtable = T, escape = F, booktabs = T)
```


## Ejercicio 3

Se presenta el código utilizado para cuando $K = 3$. Para otro $K$, solo haría falta cambiar el valor de tal variable en el código.

```{r echo=TRUE}

# Datos de entrenamiento, corresponden a las primeras 6 obs.
train <- datos3_est[1:6, c("X1", "X2", "X3")] 

# Nuevo dato (x_0)
new_data <- datos3_est[7 ,c("X1", "X2", "X3")]

# Variable respuesta Y 
labels <- datos3_est[1:6,c("Y")]

```


```{r echo=TRUE}
fit.knn <- knn(train = train, 
               test = new_data, 
               cl = labels, 
               k = 3, 
               prob = TRUE)
fit.knn
```

