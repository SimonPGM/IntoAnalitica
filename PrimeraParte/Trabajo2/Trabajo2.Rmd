---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
- \usepackage{xcolor}
- \usepackage{cancel}
- \usepackage{array}
- \usepackage{float}
- \usepackage{multirow}
output:
  pdf_document:
    number_sections: true
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: "es"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.align = 'c',  message = F)
library(tidyverse)
library(knitr)
library(kableExtra)
library(class)
library(mixlm)
library(e1071)
library(caret)
library(MASS)
library(pROC)
library(ggpubr)
```

\input{titlepage}
\thispagestyle{empty}
\tableofcontents
\listoffigures

\newpage

\listoftables

\newpage

\pagestyle{myheadings}
\setcounter{page}{3}

<!--- Simon -->

\section{Ejercicio 1} Considere el estadístico leverage:

$$
h_{ii} = \frac{1}{n} + \frac{\left(x_i - \bar{x}\right)^2}{\sum_{i'=1}^n \left(x_{i'} - \bar{x} \right)^2}
$$

Demuestre que 

$$
\frac{1}{n} \leq h_{ii} \leq 1
$$
<!--- Juanjo y Santiago -->
\newpage

\section{Ejercicio 2} Considere el conjunto de datos anexo (bank.csv) el cual tiene 17
variables. Asuma que el supervisor es la variable loan.

\subsection{Análisis descriptivo}

Como buena práctica estadística, se realiza un análisis exploratorio y descriptivo sobre la base de datos, se presentan los siguientes gráficos:

```{r}
# Lectura de datos
bank2 <- read.csv("bank.csv")
```

```{r warning=F}
bank2 <- bank2 %>% 
            mutate(housing = case_when(housing == "yes" ~ "Casa propia = Sí",
                                       housing == "no" ~ "Casa propia = No"
                                       ),
                   marital = case_when(marital == "married" ~ "Casado",
                                       marital == "divorced" ~ "Divorciado",
                                       marital == "single" ~ "Soltero"),
                   education = case_when(education == "primary" ~ "Primaria",
                                         education == "secondary" ~ "Secundaria",
                                         education == "tertiary" ~ "Terciaria",
                                         education == "unknown" ~ "Desconocido"),
                   education = fct_relevel(education, levels = c("Primaria",
                                                                 "Secundaria",
                                                                 "Terciaria",
                                                                 "Desconocido")),
                   loan = case_when(loan == "yes" ~ "Sí",
                                    loan == "no" ~ "No")
                   )

ggplot(bank2, aes(marital, fill = loan)) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(size = 5.5, angle = 0)) +
  geom_bar(position = "fill",
           color="black") +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_manual(values=c('#ff6347', '#7fff00')) +
  labs(y = "Porcentaje",
       x = "Estado civil",
       fill = "Préstamo") +
  facet_grid(housing ~ education)
```

```{r}
p_age <- ggplot(bank2, aes(x=loan, y=age, fill = loan)) +
  theme_bw() +
  geom_boxplot() +
  labs(x = "Préstamo",
       fill = "Préstamo",
       y = "Edad")

p_balance <- ggplot(bank2, aes(x= loan, y = duration, fill = loan)) +
  theme_bw() +
  geom_boxplot() + 
  labs(x = "Préstamo",
       fill = "Préstamo",
       y = "Duración del contacto")

ggarrange(p_age, p_balance, ncol = 2)
```

\subsection{Literal (a)} Cree un conjunto de datos de entrenamiento del 75\% y el
restante 25\% trátelo como datos de test o prueba.

Para la selección de cada uno de los conjuntos de datos (entrenamiento y prueba) 
se fijó la semilla 3435, luego se usó la función `sample()` de R para seleccionar
aleatoriamente $\lfloor11162 \times 0.75\rfloor = 8371$ observaciones para el 
conjunto de entrenamiento y el restante $2791$ se dejaron como datos de prueba.

```{r train_test2}
bank <- read.csv("bank.csv") %>%
  mutate(day = as.factor(day))

set.seed(3435)
n_ej2 <- dim(bank)[1]
indexes <- sample(1:n_ej2, floor(n_ej2 * 0.75))
bank_train <- bank[indexes, ]
bank_test <- bank[-indexes, ] %>%
  dplyr::select(-loan)
bank_test_response <- bank[-indexes, ] %>%
  dplyr::select(loan) %>%
  unlist() %>%
  as.factor()
```

\subsection{Literal (b)} Con los datos de entrenamiento, implemente Naive Bayes 
usando loan como el supervisor y las demás como predictores.

```{r naive_bayes}
mod_naive_bayes <- naiveBayes(loan ~ ., data = bank_train)
```

<!--- Housing, Default, Age -->

Antes de ajustar el modelo, la variable día del mes se convirtió en factor ya que por la naturaleza del problema no tiene sentido tratarla como variable numérica; luego de hacer este pequeño ajuste se construyó el modelo Naive Bayes usando la variable préstamo en función de todas las demás variables, para el ajuste del modelo se usó la función `naiveBayes()` de la librería `e1071`. A continuación se presenta unas cuantas tablas del output de dicha función.

```{r tablas_naive_bayes}
#housing
aux_housing <- mod_naive_bayes$tables$housing
rownames(aux_housing) <- c("Y = No", "Y = Sí")
kable(aux_housing %>% round(4), 
      booktabs = T, 
      caption = "Alojamiento", 
      col.names = c("No", "Sí"),
      longtable = T) %>%
  add_header_above(c(" " = 1, "Alojamiento" = 2))

#default
aux_default <- mod_naive_bayes$tables$default
rownames(aux_default) <- c("Y = No", "Y = Sí")
kable(aux_default %>% round(4), 
      booktabs = T, 
      caption = "Entrar en deuda", 
      col.names = c("No", "Sí"),
      longtable = T) %>%
  add_header_above(c(" " = 1, "Deuda" = 2))

#age
aux_age <- mod_naive_bayes$tables$age
rownames(aux_age) <- c("Y = No", "Y = Sí")
kable(aux_age %>% round(4), 
      booktabs = T, 
      caption = "Edad", 
      col.names = c("Media", "Desviación estandar"),
      longtable = T) %>%
  add_header_above(c(" " = 1, "Edad" = 2))

rm(aux_housing, aux_age, aux_default)
```

Se hace la aclaración de que las filas de cada tabla representan los valores de 
la variable respuesta, en este caso como se está en un problema de clasificación
binario sus posibles valores son "Sí" y "No". Para los inputs numéricos retorna 
una tabla donde la primera columna es la media de dicha variable y la segunda es
su desviación estandar; en el caso de los inputs categóricos se retorna una tabla
con las probabilidades condicionales dada una clase de la variable respuesta.

\subsection{Literal (c)} Con los datos de entrenamiento, implemente Knn usando loan 
como el supervisor y las demás como predictores. Ensaye con varios valores de $K$ y
reporte solo uno de acuerdo a su preferencia. Observe que algunas variables son
categóricas y se deben crear variables dummies.

Para la construcción del modelo KNN se usaron las funciones `trainControl()` y
`train(..., method = "knn")` de la librería `caret`. La función `trainControl()` 
se encarga de controlar los parámetros de entrenamiento que usará posteriormente
la función `train()` la cual es la protagonista en el proceso de ajuste del modelo
KNN. `train()` puede recibir un objeto de la clase formula para ajustar el modelo 
y ella se encarga internamente de realizar el proceso de creación de variables 
dummies para que el algoritmo funcione correctamente; dicha función puede ajustar
modelos con diversos métodos, en particular KNN el cual fue especificado en el
argumento method para este propósito. La función `train()` realiza un remuestreo
de la base de datos un número preespecificado de veces  $m$ ingresada para 
calcular el $K$ óptimo, por lo tanto el MSE es calculado $m$ veces, esto permite
obtener tanto la media como la desviación estandar del MSE para distintos 
valores de $K$ y dicho valor no necesariamente va a concordar con el MSE del 
train que es calculado sobre la base de datos de entrenamiento completo, sin 
embargo los valores deben ser muy similares. 

Dada la complejidad de interpretación y graficación para este problema por la 
cantidad de variables que se tiene, se presenta a continuación una tabla con el
resultado del Accuracy para distintos valores de K. 

```{r mod_knn_ej2}
ctrl <- trainControl(method = "LGOCV", p = 0.9, number = 15)
#ajuste del modelo
# mod_knn <- train(loan ~ .,
#                  data       = bank_train,
#                  method     = "knn",
#                  preProcess = c("center","scale"),
#                  trControl  = ctrl,
#                  metric     = "Accuracy")
# saveRDS(mod_knn, file = "mod_knn.rds")
mod_knn <- readRDS("mod_knn.rds")
kable(mod_knn$results[, c("k", "Accuracy", "AccuracySD")] %>% round(4), 
      longtable = T,
      booktabs = T,
      col.names = c("K", "Exactitud", "Exactitud - SD"),
      caption = "Métricas para distintos valores de K")
```

\subsection{Literal (d)} Con los datos de entrenamiento, implemente regresión 
logística usando loan como supervisor y las demás como predictores. 

```{r mod_logistico}
bank_train_logit <- bank_train %>% 
  mutate(loan = if_else(loan == "yes", 1, 0))
mod_logit <- stats::glm(loan ~ ., data = bank_train_logit, family = "binomial")
```

El ajuste del modelo logístico se realizó usando la función `glm()` de la librería
básica de R `stats`, la cual sirve para ajustar modelos lineales generalizados, se
especificó la familia como "binomial" para este propósito. La función logit fue
usada como enlace para garantizar que las imágenes estén mapeadas a valores en el
intervalo $(0, 1)$, si dicho valor es mayor a $0.5$ se clasifica como "Sí", de 
lo contrario se clasifica como "No".

```{r marital}
resumen <- summary(mod_logit)
marital_table <-  resumen$coefficients[c("marital1", "marital2"), ] %>%
  round(4)
rownames(marital_table) <- c("Casado", "Soltero")
kable(marital_table, longtable = T, booktabs = T,
      col.names = c("Estimación", "Error estándar", "$Z_0$", "Valor-p"),
      caption = "Coeficientes del modelo LR para la variable estado civil",
      escape = F)
```

La variable estado civil es categórica con 3 niveles los cuales son divorciado, casado y soltero; se utiliza el nivel divorciado como referencia. A partir de los coeficientes estimados en el modelo de regresión logística se pueden obtener las siguientes estimaciones para algunas razones de odds: 

\begin{itemize}
\item La razón de odds que contrasta aquellos que están casados en comparación con
aquellos que están divorciados se obtiene como 
$\exp{(0.1888)} = `r exp(0.1888) %>% round(4)`$, es decir que los casados 
presentan $100\% \times (\exp{(0.1888)} - 1) = `r 100*(exp(0.1888) - 1) %>% round(4)`\%$ más de chances de obtener un préstamo respecto a los divorciados.
\item La razón de odds que contrasta aquellos que están solteros en comparación 
con aquellos que están divorciados se obtiene como 
$\exp{(0.1146)} = `r exp(0.1146) %>% round(4)`$, es decir que los solteros 
presentan 
$100\% \times (\exp{(0.1146)} - 1) = `r 100*(exp(0.1146) - 1) %>% round(4)`\%$ 
más de chances de obtener un préstamo respecto a los divorciados. 
\end{itemize}


\subsection{Literal (e)} Con los datos de entrenamiento, implemente LDA usando 
loan como supervisor y las demás como predictores.

Para ajustar el modelo LDA se usó la función `lda()` de la librería `MASS`. 

```{r lda}
mod_lda <- lda(loan ~ ., data = bank_train)
```

```{r lda-viz}
# Se lee la bd con los resultados de la predicción de test
# Tiene info interesante
pred_lda <- read.csv("pred_lda_test.csv")

# Se unen las predicciones con la BD test
test_y <- cbind(bank_test, pred_lda)
```

La salida del modelo LDA entrega la clase en que fue clasificada cada observación y la probabilidad a posteriori, siguiendo el paradigma bayesiano de que la observación sea de una u otra clase. Se muestra tal salida para las primeros cinco observaciones del conjunto de prueba:

```{r}
kable(pred_lda[1:5,1:4],
      longtable = T,
      booktabs = T,
      col.names = c("Obs", "Clase", "Posterior - No", "Posterior - Sí"),
      caption = "Primeras cinco filas de la salida del modelo LDA")
```


Se muestra gráficamente la clasificación que realiza el modelo según covariables.

```{r lda-viz 1}

# Visualización
ggplot(test_y, aes(x = age, y = duration, shape = class, color = class)) +
  geom_point(size=0.9) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(size = 5.5, angle = 0)) +
  scale_fill_manual(values=c('#ff6347', '#7fff00')) +
  labs(title = "Clasificación que realiza LDA según covariables") +
  facet_grid(housing ~ education)
```







\subsection{Literal (f)} Con los datos de entrenamiento, para cada uno de los 
métodos anteriores, calcule el training-MSE, la matriz de confusión y grafique 
la curva ROC.

\subsubsection{Errores cuadráticos medios de entrenamiento}

```{r metricas_f, message=F}
validacion <- function(observados, ajustados, caption = " "){
  accuracy <- Metrics::accuracy(observados, ajustados)
  matriz_confusion <- table(Observados = observados, Ajustados = ajustados)
  rownames(matriz_confusion) <- c("Y = No", "Y = Sí")
  matriz_confusion <- kable(matriz_confusion,
                            longtable = T, booktabs = T, caption = caption,
                            col.names = c("No", "Sí")) %>%
  add_header_above(c(" " = 1, "Valores predichos" = 2))
  overall <- list(Accuracy = accuracy, Confusion_matrix = matriz_confusion)
  return(overall)
}

label_response <- which(names(bank_train) == "loan")
# Naive Bayes
pred_nb_train <- predict(mod_naive_bayes, 
                            newdata = bank_train[, -label_response])
# KNN
pred_knn_train <- predict(mod_knn, bank_train[, -label_response])

#Logistica
pred_logit_train <- ifelse(predict(mod_logit, bank_train[, -label_response],
                            type = "response") > 0.5, "yes", "no")
#LDA
pred_lda_train <- predict(mod_lda, bank_train[, -label_response])

#Exactitud
exactitud <- cbind(validacion(bank_train[, label_response], pred_nb_train, 
           caption = "Naive Bayes")$Accuracy,
           validacion(bank_train[, label_response], pred_knn_train, 
           caption = "Naive Bayes")$Accuracy,
           validacion(bank_train[, label_response], pred_logit_train, 
           caption = "Naive Bayes")$Accuracy,
           validacion(bank_train[, label_response], pred_lda_train$class, 
           caption = "Naive Bayes")$Accuracy) %>%
  round(4) %>%
  as.data.frame() 

colnames(exactitud) <- c("Naive Bayes", "KNN", "Logística", "LDA")
rownames(exactitud) <- c("Train-MSE")

kable(exactitud, longtable = T, booktabs = T, 
      caption = "MSE en los datos de entrenamiento")
```

\subsubsection{Matrices de confusión de entrenamiento}

```{r matrices_confusion_f, message=F}
#Matrices de confusión
validacion(bank_train[, label_response], pred_nb_train, 
           caption = "Naive Bayes")$Confusion_matrix
validacion(bank_train[, label_response], pred_knn_train, 
           caption = "KNN")$Confusion_matrix
validacion(bank_train[, label_response], pred_logit_train, 
           caption = "Regresión logística")$Confusion_matrix
validacion(bank_train[, label_response], pred_lda_train$class,
           caption = "LDA")$Confusion_matrix
```

\subsubsection{Curvas ROC de entrenamiento}

```{r curvas_roc_train, fig.cap="Curvas ROC", fig.pos = "H"}
numeric_train_label <- ifelse(bank_train[, label_response] == "yes", 1, 0)
numeric_train_nb <- ifelse(pred_nb_train == "yes", 1, 0)

#Curvas ROC
#Naive - Bayes
roc_nb_train <- roc(numeric_train_label, numeric_train_nb)
p1_train <- ggroc(roc_nb_train) +
  geom_segment(aes(x = 1, xend = 0,
                   y = 0, yend = 1), color = "tomato", linetype = "dashed") +
  labs(title = "Naive - Bayes", x = "Especificidad",
       y = "Sensibilidad") + 
  theme_minimal()

#KNN
numeric_train_knn <- ifelse(pred_knn_train == "yes", 1, 0)
roc_knn_train <- roc(numeric_train_label, numeric_train_knn)
p2_train <- ggroc(roc_knn_train) +
  geom_segment(aes(x = 1, xend = 0,
                   y = 0, yend = 1), color = "darkblue", linetype = "dashed") +
  labs(title = "KNN", x = "Especificidad",
       y = "Sensibilidad") + 
  theme_minimal()

#Logistica
numeric_logit_train <- ifelse(pred_logit_train == "yes", 1, 0)

roc_logit_train <- roc(numeric_train_label, numeric_logit_train)
p3_train <- ggroc(roc_logit_train) +
  geom_segment(aes(x = 1, xend = 0,
                   y = 0, yend = 1), color = "purple", linetype = "dashed") +
  labs(title = "Regresión logística", x = "Especificidad",
       y = "Sensibilidad") + 
  theme_minimal()

#LDA
numeric_lda_train <- ifelse(pred_lda_train$class == "yes", 1, 0)

roc_lda_train <- roc(numeric_train_label, numeric_lda_train)
p4_train <- ggroc(roc_lda_train) +
  geom_segment(aes(x = 1, xend = 0,
                   y = 0, yend = 1), color = "darkgreen", linetype = "dashed") +
  labs(title = "LDA", x = "Especificidad",
       y = "Sensibilidad") + 
  theme_minimal()

ggpubr::ggarrange(p1_train, p2_train, p3_train, p4_train)

rm(numeric_train_nb, numeric_train_knn, numeric_logit_train, numeric_lda_train)

```

\subsection{Literal (g)}

\subsubsection{Errores cuadráticos medios de prueba}

```{r metricas_g, message=F}
# Naive Bayes
pred_nb_test <- predict(mod_naive_bayes, 
                            newdata = bank_test)
# KNN
pred_knn_test <- predict(mod_knn, bank_test)

#Logistica
pred_logit_test <- ifelse(predict(mod_logit, bank_test,
                            type = "response") > 0.5, "yes", "no")
#LDA
pred_lda_test <- predict(mod_lda, bank_test)
#write.csv(pred_lda_test, file = "pred_lda_test.csv")

#Exactitud
exactitud_test <- cbind(validacion(bank_test_response, pred_nb_test, 
           caption = "Naive Bayes")$Accuracy,
           validacion(bank_test_response, pred_knn_test, 
           caption = "Naive Bayes")$Accuracy,
           validacion(bank_test_response, pred_logit_test, 
           caption = "Naive Bayes")$Accuracy,
           validacion(bank_test_response, pred_lda_test$class, 
           caption = "Naive Bayes")$Accuracy) %>%
  round(4) %>%
  as.data.frame() 

colnames(exactitud_test) <- c("Naive Bayes", "KNN", "Logística", "LDA")
rownames(exactitud_test) <- c("Test-MSE")

kable(exactitud_test, longtable = T, booktabs = T, 
      caption = "MSE en los datos de prueba")
```

\subsubsection{Matrices de confusión de prueba}

```{r matrices_confusion_g}
#Matrices de confusión
validacion(bank_test_response, pred_nb_test, 
           caption = "Naive Bayes")$Confusion_matrix
validacion(bank_test_response, pred_knn_test, 
           caption = "KNN")$Confusion_matrix
validacion(bank_test_response, pred_logit_test, 
           caption = "Regresión logística")$Confusion_matrix
validacion(bank_test_response, pred_lda_test$class,
           caption = "LDA")$Confusion_matrix
```

\subsubsection{Curvas ROC de prueba}

```{r curvas_roc_test, fig.cap="Curva ROC", fig.pos="H"}
numeric_test_label <- ifelse(bank_test_response == "yes", 1, 0)
numeric_test_nb <- ifelse(pred_nb_test == "yes", 1, 0)







#Curvas ROC
#Naive - Bayes
roc_nb_test <- roc(numeric_test_label, numeric_test_nb)
auc_nb <- round(auc(numeric_test_label, numeric_test_nb),4)

p1_test <- ggroc(roc_nb_test) +
  geom_segment(aes(x = 1, xend = 0,
                   y = 0, yend = 1), color = "tomato", linetype = "dashed") +
  labs(title = "Naive - Bayes", x = "Especificidad",
       y = "Sensibilidad") + 
  theme_minimal() +
  annotate("text", x = 0.75, y = 0.75, label = paste("AUC = ", auc_nb))

#KNN
numeric_test_knn <- ifelse(pred_knn_test == "yes", 1, 0)
auc_knn <- round(auc(numeric_test_label, numeric_test_knn),4)
roc_knn_test <- roc(numeric_test_label, numeric_test_knn)

p2_test <- ggroc(roc_knn_test) +
  geom_segment(aes(x = 1, xend = 0,
                   y = 0, yend = 1), color = "darkblue", linetype = "dashed") +
  labs(title = "KNN", x = "Especificidad",
       y = "Sensibilidad") + 
  theme_minimal()  +
  annotate("text", x = 0.75, y = 0.75, label = paste("AUC = ", auc_knn))

#Logistica
numeric_logit_test <- ifelse(pred_logit_test == "yes", 1, 0)
auc_logit <- round(auc(numeric_test_label, numeric_logit_test),4)

roc_logit_test <- roc(numeric_test_label, numeric_logit_test)
p3_test <- ggroc(roc_logit_test) +
  geom_segment(aes(x = 1, xend = 0,
                   y = 0, yend = 1), color = "purple", linetype = "dashed") +
  labs(title = "Regresión logística", x = "Especificidad",
       y = "Sensibilidad") + 
  theme_minimal() +
  annotate("text", x = 0.75, y = 0.75, label = paste("AUC = ", auc_logit))

#LDA
numeric_lda_test <- ifelse(pred_lda_test$class == "yes", 1, 0)
roc_lda_test <- roc(numeric_test_label, numeric_lda_test)
auc_lda <- round(auc(numeric_test_label, numeric_lda_test),4)

p4_test <- ggroc(roc_lda_test) +
  geom_segment(aes(x = 1, xend = 0,
                   y = 0, yend = 1), color = "darkgreen", linetype = "dashed") +
  labs(title = "LDA", x = "Especificidad",
       y = "Sensibilidad") + 
  theme_minimal() +
  annotate("text", x = 0.75, y = 0.75, label = paste("AUC = ", auc_lda))

ggpubr::ggarrange(p1_test, p2_test, p3_test, p4_test)

#rm(numeric_test_nb, numeric_test_knn, numeric_logit_test, numeric_lda_test)

```

\subsection{Literal (h)}

¿Con cuál modelo observó un mejor desempeño y porqué?

En general, los modelos registran un buen desempeño en relación con la métrica de especificidad, sin embargo, tienen muy baja sensibilidad: La probabilidad de que los modelos identifiquen correctamente como loan = Sí cuando el sujeto es en realidad  loan = Sí es baja. El modelo \textbf{Naive Bayes} presenta los mejores resultados en cuanto a esta última métrica, y aunque presenta un valor más bajo en cuanto a la especificidad, tiene el AUC (área bajo la curva ROC) más grande, por lo tanto \textbf{se elige como el de mejor desempeño.} 

En una situación real, según los requerimiento de negocio, se debería identificar si los falsos positivos o verdaderos negativos son más costosos en términos de recursos del problema.

```{r borrando_todo}
#rm(list = ls())
```






<!---Simon y Gaviria -->
\newpage
\section{Ejercicio 3} Considere el conjunto de datos anexo 
(costumer loan details.csv) el cual tiene 12 variables incluyendo el ID. 
Asuma que el supervisor es la variable income.

Para dar inicio, se cargan los datos y se presentan la estructura de la base como se muestra en la siguiente tabla:

```{r cargando datos}
datos <- read.csv("costumer_loan_details.csv", header = T, sep = ",", dec = ".")
```

```{r mostrando datos}
kable(head(datos), caption = "Estructura de los datos", align = 'c', longtable = T)
```

\subsection{Literal (a)} Cree un conjunto de datos de entrenamiento del 
75\% y el restante 25\% trátelo como datos de test o prueba

Así, se procede a particionar aleatoriamente la base en datos de entrenamiento y prueba, dejando un 75% de los datos para el entrenamiento de modelos, y el 25% restante para las pruebas de rendimiento correspondientes. 

```{r dividiendo en train y test}
set.seed(7)
index <- sample(1:114, 86)
datos.train <- datos[index,]
datos.test <- datos[-index,]
```

Con esto, se obtienen 86 observaciones en los datos de entrenamiento y 28 observaciones en la base de prueba

\subsection{Literal (b)} Con los datos de entrenamiento, implemente Knn 
(con al menos tres valores para $K$) usando income como el supervisor y 
debts como predictor. Grafique e interprete.

Dicho lo anterior, se procede a obtener tres modelos usando regresión KNN donde k tomará los valores de 5, 10, 20 y 50 respectivamente. El resultado obtenido se muetra como sigue:

```{r modelando knn reg}
knn35 <-  FNN::knn.reg(datos.train$income, 
                      data.frame(income = seq(min(datos.train$income), 
                                              max(datos.train$income), 
                                              by = 0.02)), 
                      datos.train$debts,
                      5)
knn310 <- FNN::knn.reg(datos.train$income, 
                      data.frame(income = seq(min(datos.train$income), 
                                              max(datos.train$income), 
                                              by = 0.02)), 
                      datos.train$debts,
                      10)
knn320 <- FNN::knn.reg(datos.train$income, 
                      data.frame(income = seq(min(datos.train$income), 
                                              max(datos.train$income), 
                                              by = 0.02)), 
                      datos.train$debts,
                      20)
knn350 <- FNN::knn.reg(datos.train$income, 
                      data.frame(income = seq(min(datos.train$income), 
                                              max(datos.train$income), 
                                              by = 0.02)), 
                      datos.train$debts,
                      50)
```

```{r graficando knn reg}
pknn35 <- ggplot(datos, aes(income, debts)) + 
          geom_point() +
          geom_path(data = data.frame(income = seq(min(datos.train$income),                                                               max(datos.train$income),
                                                   by=0.02),                                                                 debts = knn35$pred), 
                    colour = "orange") + 
          labs(title = "Regresión KNN para Income vs Debts", caption = "K = 5") +
          xlab("Income") +
          ylab("Debts") + 
          theme_minimal() + 
          theme(plot.title = element_text(hjust = 0.5))

pknn310 <-ggplot(datos, aes(income, debts)) + 
          geom_point() +
          geom_path(data = data.frame(income = seq(min(datos.train$income),                                                               max(datos.train$income),
                                                   by=0.02),                                                                 debts = knn310$pred), 
                    colour = "red") + 
          labs(title = "Regresión KNN para Income vs Debts", caption = "K = 10") +
          xlab("Income") +
          ylab("Debts") + 
          theme_minimal() + 
          theme(plot.title = element_text(hjust = 0.5))

pknn320 <-ggplot(datos, aes(income, debts)) + 
          geom_point() +
          geom_path(data = data.frame(income = seq(min(datos.train$income),                                                               max(datos.train$income),
                                                   by=0.02),                                                                 debts = knn320$pred), 
                    colour = "blue") + 
          labs(title = "Regresión KNN para Income vs Debts", caption = "K = 20") +
          xlab("Income") +
          ylab("Debts") + 
          theme_minimal() + 
          theme(plot.title = element_text(hjust = 0.5))

pknn350<-ggplot(datos, aes(income, debts)) + 
          geom_point() +
          geom_path(data = data.frame(income = seq(min(datos.train$income),                                                               max(datos.train$income),
                                                   by=0.02),                                                                 debts = knn350$pred), 
                    colour = "green") + 
          labs(title = "Regresión KNN para Income vs Debts", caption = "K = 50") +
          xlab("Income") +
          ylab("Debts") + 
          theme_minimal() + 
          theme(plot.title = element_text(hjust = 0.5))
  
ggpubr::ggarrange(pknn35,pknn310,pknn320,pknn350, nrow = 2, ncol = 2)
```

De acá se puede ver fácilmente que a medida que aumenta el valor de k, la curva del modelo pierde su flexibilidad por lo cual, modelos con valores altos de k pueden llegar a explicar mal la respuesta. Así entonces, para no incurrir en sobreajustes indeseados (y posiblemente llegar a modelos incapaces de generalizar) se puede escoger el modelo de regresión KNN implementado con 20 vecinos más cercanos.

\subsection{Literal (c)} Con los datos de entrenamiento, implemente regresión 
lineal simple usando income como el supervisor y debts como predictor. Grafique 
e interprete.

Ahora, es de interés ajustar un modelo de regresión lineal simple donde la respuesta y la covariable en cuestión quedan definidos por debts e income respectivamente, el resultado obtenido se representa como sigue:

El modelo obtenido queda determinado por la siguiente expresión

```{r ajustando regresion}
mod3 <- stats::lm(debts~income, data = datos.train)
```

\begin{center}
$\widehat{debts} = -882.11 +  0.37 * \text{income}$
\end{center}

Para visualizar el ajuste de este modelo a los datos originales se plantea el siguiente gráfico:

```{r graficando regresion, results ='hide', message=F}
ggplot(datos.train, aes(income, debts)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = F, colour = "orange") + 
  labs(title = "Regresión ajustada a los datos Income vs Debts") +
  xlab("Income") + 
  ylab("Debts") +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))
```

De este gráfico se puede observar en primera instancia que, la relación entre la deuda y los ingresos es directamente proporcional, por lo cual se puede afirmar que a mayores ingresos, mayor es la deuda. En general puede apreciarse que el ajuste de la recta regresora al conjunto de datos es buena, sin embargo, se debe observar que algunos de los puntos allí presentes logran alejarse bastante de la curva, este tópico es suceptible a un análisis de influencia y balanceo.

\subsection{Literal (d)} Use los respectivos ajustes de cada uno de los 
modelos anteriores y con el conjunto de prueba, calcule el test-MSE, ¿Qué observa?

Recuérdese que el MSE es una medida de desempeño para modelos de diferentes tipos, y en este caso se desean comparar los modelos anteriormente construídos utilizando esta métrica, siendo el mejor modelo aquel que tenga el menor MSE. Esta medida de desempeño tiene la siguiente especificación:

\begin{center}
$ECM = \frac{1}{n} \sum_{i=1}^{n}(\hat{y}_{i}-y_{i})^2$
\end{center}

Así entonces, evaluando todos los modelos en el conjunto de prueba se obtienen los siguientes resultados:

```{r mostrando desempeño}
knntest5 <- as.numeric(FNN::knn.reg(datos.train$income, 
                         data.frame(income= datos.test$income), 
                         datos.train$debts,
                         5)$pred)
knntest10 <- as.numeric(FNN::knn.reg(datos.train$income, 
                         data.frame(income= datos.test$income), 
                         datos.train$debts,
                         10)$pred)
knntest20 <- as.numeric(FNN::knn.reg(datos.train$income, 
                         data.frame(income= datos.test$income), 
                         datos.train$debts,
                         20)$pred)
knntest50 <- as.numeric(FNN::knn.reg(datos.train$income, 
                         data.frame(income= datos.test$income), 
                         datos.train$debts,
                         50)$pred)
regtest <- predict(mod3, data.frame(income= datos.test$income))

mse <- function(real, predicted){
  return(mean((real-predicted)^2))}

mse.table <- data.frame("Modelo" = "MSE",
                        "Regresión" = mse(datos.test$debts, regtest),
                        "$K=5$" = mse(datos.test$debts, knntest5),
                        "$k=10$" = mse(datos.test$debts, knntest10),
                        "$K=20$" = mse(datos.test$debts, knntest20),
                        "$K=50$" = mse(datos.test$debts, knntest50))

kable(mse.table, caption = "Resultados de Desempeño", align = 'c', longtable = T)
```

Así, se puede apreciar que el menor MSE lo reporta el modelo de regresión lineal simple. El mejor modelo de regresión KNN fué aquel que se escogió con 10 vecinos más cercanos, dado que entre este tipo de modelos fué el que menor MSE presentó. Todo este resultado se obtuvo a partir de los datos de test.

\subsection{Literal (e)} Usando todos los datos y regresión lineal múltiple 
seleccione un modelo usando forward, backward y stepwise.

Ahora, se desea obtener un modelo de regresión utilizando métodos de selección como backward, forward y stepwise.

Así entonces, para comenzar a realizar backward, se ajusta inicialmente un modelo saturado y se comienzan a eliminar regresores con una significancia menor a la usual en el modelo, con lo cual se obtiene finalmente lo siguiente:

```{r haciendo backward, results='hide'}
mod3e <- stats::lm(debts~state+gender+age+race+marital_status+occupation+credit_score+income+loan_type+loan_decision_type, data = datos)
mod3eback <- backward(mod3e, 0.05)
dfback <- data.frame("Covariable"= names(mod3eback$coefficients), 
                     "Estimación" = as.numeric(mod3eback$coefficients))
```

```{r imprimiendo resultados 1}
kable(dfback, caption = "Variables para el modelo final", align = 'c', longtable = T)
```

Así, se puede observar que después de hacer la selección hacia atrás con un nivel de significancia usual se obtiene que las covariables eliminadas en este caso son: occupation, state, gender, race y marital_status.

Por otro lado, para realizar forward o selección hacia adelante se parte un modelo sin covariables, es decir, solo teniendo en cuenta el intercepto. Posteriormete se debe especificar un scope de variables para definir hasta donde hacer la selección hacia adelante, lo obtenido se muestra como sigue:

```{r haciendo forward, results='hide'}
mod3eforw <- forward(mod3e, 0.05)
dfforw <- data.frame("Covariable"= names(mod3eforw$coefficients), 
                     "Estimación" = as.numeric(mod3eforw$coefficients))
```

```{r imprimiendo resultados 2}
kable(dfforw, caption = "Variables para el modelo final", align = 'c', longtable = T)
```

Así, gracias al método de selección hacia adelante se llega a exactamente el mismo modelo obtenido en el desarrollo anterior, todo esto agregando variables que supongan un nivel de significancia usual.

Por último, se intentará llegar a un último modelo, pero esta vez usando el método stepwise, ingresando y eliminando variables a un nivel de significancia de $\alpha = 0.05$, con lo cual se obtiene el siguiente resultado:

```{r haciendo stepwise, results = 'hide'}
mod3estep <- stepWise(mod3e, alpha.enter = 0.05, alpha.remove = 0.05)

dfforw <- data.frame("Covariable"= names(mod3estep$coefficients), 
                     "Estimación" = as.numeric(mod3estep$coefficients))
```

```{r imprimendo resultados 3}
kable(dfforw, caption = "Variables para el modelo final", align = 'c', longtable = T)
```

Y así, de nuevo se obtiene exactamente el mismo modelo que en los procedimientos anteriores. 

\subsection{Literal (f)} Seleccione uno de los modelos del paso anterior y 
responda con argumentación la pregunta: ¿ajusta bien dicho modelo?

Dado que se obtiene exactamente el mismo modelo usando los diferentes procedimientos mencionados para selección de variables, se selecciona este y para hacer alguna comparación, se procede a presentar el AIC y el $R^2_{adj}$ del modelo saturado y del modelo en cuestión:

```{r desempeño de los modelos anteriores}
kable(data.frame(c("Saturado", "Depurado"),
                 c(AIC(mod3e),AIC(mod3eback)),
                 round(c(summary(mod3e)$r.squared, summary(mod3eback)$r.squared),3)),
      col.names = c("Modelo", "AIC", "${R^2}_{adj}$"),
      escape = F,
      caption = "Comparación de modelos",
      align = 'c',
      longtable = T)
```

Así, se puede decidir por cualquier modelo de estos dos teniendo en cuenta alguna de las métricas presentadas anteriormente. Sin embargo, en este caso por parsimonia y teniendo en cuenta el criterio de información de Akaike, se escoje el modelo obtenido realizando el debido procedimeinto de selección de variables.


